{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset preparing\n",
    "1. download data.zip to project root folder\n",
    "2. move data.zip and unzip in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"./data/coco/fashion\", exist_ok=True)\n",
    "os.rename(\"./data.zip\", \"./data/coco/fashion/data.zip\")\n",
    "\n",
    "!unzip ./data/coco/fashion/data.zip -d ./data/coco/fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split validation dataset\n",
    "- 학습 데이터셋의 20%를 validation dataset으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "coco_file = './data/coco/fashion/train.json'\n",
    "output_dir = './data/coco/fashion'\n",
    "train_ratio = 0.8\n",
    "\n",
    "def save_coco(file_path, anno_dict, image_dict, categories, image_id_list):\n",
    "    coco = {'categories': categories}\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for image_id in image_id_list:\n",
    "        images.append(image_dict[image_id])\n",
    "        if image_id not in anno_dict:\n",
    "            print(\"skip! image id  not in anno dict. image_id: {}\".format(image_id))\n",
    "            continue\n",
    "        for anno in anno_dict[image_id]:\n",
    "            annotations.append(anno)\n",
    "\n",
    "    coco['annotations'] = annotations\n",
    "    coco['images'] = images\n",
    "    json.dump(coco, open(file_path, \"w+\"))\n",
    "    \n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"loading coco dataset\")\n",
    "coco = json.load(open(coco_file))\n",
    "print(\"loaded\")\n",
    "\n",
    "images = coco['images']\n",
    "annotations = coco['annotations']\n",
    "categories = coco['categories']\n",
    "\n",
    "image_id_list = []\n",
    "image_dict = {}\n",
    "for image in images:\n",
    "    image_id = image['id']\n",
    "    image_id_list.append(image_id)\n",
    "    image_dict[image_id] = image\n",
    "\n",
    "anno_dict = {}\n",
    "for anno in annotations:\n",
    "    image_id = anno['image_id']\n",
    "    if image_id not in anno_dict:\n",
    "        anno_dict[image_id] = []\n",
    "    anno_dict[image_id].append(anno)\n",
    "\n",
    "split_idx = round(len(image_id_list) * train_ratio)\n",
    "train_image_id_list = image_id_list[:split_idx]\n",
    "val_image_id_list = image_id_list[split_idx:]\n",
    "\n",
    "save_coco(os.path.join(output_dir, \"train_split.json\"), anno_dict, image_dict, categories, train_image_id_list)\n",
    "save_coco(os.path.join(output_dir, \"val_split.json\"), anno_dict, image_dict, categories, val_image_id_list)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move train & test images to each folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "\n",
    "def move_images_to_dir(image_root_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_dirs = glob.glob(os.path.join(image_root_dir, \"*\"))\n",
    "\n",
    "    for i, image_dir in enumerate(image_dirs):\n",
    "        image_files = glob.glob(os.path.join(image_dir, \"*\"))\n",
    "        for j, image_path in enumerate(image_files):\n",
    "            if j % 100 == 0:\n",
    "                print(\"moving dir {}/{}, files {}/{}\".format(i, len(image_dirs), j, len(image_files)))\n",
    "            shutil.move(image_path, output_dir)\n",
    "    print(\"done\")\n",
    "\n",
    "move_images_to_dir(\"./data/coco/fashion/train\", \"./data/coco/fashion/train_images\")\n",
    "move_images_to_dir(\"./data/coco/fashion/test\", \"./data/coco/fashion/test_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "- Detection Model: DetectoRS\n",
    "- backbone: Resnet50\n",
    "- 4 steps training(Transfer learning from pretrained model with imagenet and 3times FineTunings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 1 Transfer Learning\n",
    "- image scale: 1333, 800\n",
    "- trained with splited traininig data\n",
    "- optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
    "- training epoch: 12epoch\n",
    "- transfer learning from pretrained torchvision://resnet50 with imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python tools/train.py \\\n",
    "configs/fashion_detectors_tr1.py\n",
    "\n",
    "# multiple gpus training\n",
    "#! OMP_NUM_THREADS=1 CUDA_VISIBLE_DEVICES=0,1 \\\n",
    "#bash tools/dist_train.sh \\\n",
    "#configs/fashion_detectors_tr1.py 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 2 FineTuning\n",
    "- image scale: 800, 800\n",
    "- trained with all traininig data\n",
    "- finetuning from work_dirs/fashion_detectors/epoch_12.pth\n",
    "- optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
    "- training epoch: from 12epoch to 24epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/fashion_mmdetection/epoch_12.pth -P ./work_dirs/fashion_detectors/\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python tools/train.py \\\n",
    "configs/fashion_detectors_tr2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 3 FineTuning\n",
    "- image scale: 800, 800\n",
    "- trained with all traininig data\n",
    "- finetuning from work_dirs/fashion_detectors/epoch_24.pth\n",
    "- optimizer = dict(type='SGD', lr=0.004, momentum=0.9, weight_decay=0.0001)\n",
    "- training epoch: from 24epcoh to 36epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/fashion_mmdetection/epoch_24.pth -P ./work_dirs/fashion_detectors/\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python tools/train.py \\\n",
    "configs/fashion_detectors_tr3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 4 FineTuning\n",
    "- image scale: 800, 800\n",
    "- trained with all traininig data\n",
    "- finetuning from work_dirs/fashion_detectors/epoch_34.pth\n",
    "- optimizer = dict(type='SGD', lr=0.002, momentum=0.9, weight_decay=0.0001)\n",
    "- training epoch: from 34epoch to 50epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/fashion_mmdetection/epoch_34.pth -P ./work_dirs/fashion_detectors/\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python tools/train.py \\\n",
    "configs/fashion_detectors_tr4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2 models\n",
    "1. epoch 34 model (top 1 model)\n",
    "2. epoch 50 model (top 2 model)\n",
    "\n",
    "- soft_nms\n",
    "- score_thr: 0.81\n",
    "\n",
    "- 리더보드 기준 약 7.8% 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 파라미터 (실행할 필요 없음)\n",
    "test_cfg = dict(\n",
    "    rpn=dict(\n",
    "        nms_across_levels=False,\n",
    "        nms_pre=1000,\n",
    "        nms_post=1000,\n",
    "        max_num=1000,\n",
    "        nms_thr=0.7,\n",
    "        min_bbox_size=0),\n",
    "    rcnn=dict(\n",
    "        score_thr=0.81,\n",
    "        nms=dict(type='soft_nms', iou_threshold=0.5),\n",
    "        max_per_img=100,\n",
    "        mask_thr_binary=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/fashion_mmdetection/epoch_34.pth -P ./work_dirs/fashion_detectors/\n",
    "!wget -nc https://font-recognizer-bucket.s3.us-east-2.amazonaws.com/resource/kaggle/fashion_mmdetection/epoch_50.pth -P ./work_dirs/fashion_detectors/\n",
    "    \n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python tools/test.py \\\n",
    "configs/fashion_detectors_test.py \\\n",
    "work_dirs/fashion_detectors/epoch_34.pth \\\n",
    "--format-only \\\n",
    "--eval-options \"jsonfile_prefix=./work_dirs/fashion_detectors/e34\"\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 \\\n",
    "python tools/test.py \\\n",
    "configs/fashion_detectors_test.py \\\n",
    "work_dirs/fashion_detectors/epoch_50.pth \\\n",
    "--format-only \\\n",
    "--eval-options \"jsonfile_prefix=./work_dirs/fashion_detectors/e50\"\n",
    "\n",
    "# multiple gpus training\n",
    "# ! OMP_NUM_THREADS=1 CUDA_VISIBLE_DEVICES=0,1 \\\n",
    "# bash tools/dist_test.sh \\\n",
    "# configs/fashion_detectors_test.py work_dirs/fashion_detectors/epoch_34.pth 2 --format-only --eval-options \"jsonfile_prefix=./work_dirs/fashion_detectors/e34\"\n",
    "\n",
    "# ! OMP_NUM_THREADS=1 CUDA_VISIBLE_DEVICES=0,1 \\\n",
    "# bash tools/dist_test.sh \\\n",
    "# configs/fashion_detectors_test.py work_dirs/fashion_detectors/epoch_50.pth 2 --format-only --eval-options \"jsonfile_prefix=./work_dirs/fashion_detectors/e50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble 2 models, mask post processing\n",
    "- 각 모델의 테스트 결과인 마스크들을 서로 비교하여 새로운 마스크를 추가하거나 동일한 마스크를 머지하는 과정\n",
    "- 앙상블 하려는 모든 모델의 마스크들을 이미지 별로 취합 후, 이미지에 mask가 한개만 있으면 무조건 mask를 결과에 포함시킨다.\n",
    "- 이미지에 mask가 여러개 있으면 모든 마스크끼리 iou를 비교하여 iou가 0.7이상일 경우에는 2개의 마스크를 merge(단순 더하기)하고,\n",
    "- 첫번째로 입력한 모델의 카테고리로 결과에 포함시킨다.\n",
    "- merge되지 않는 마스크들은 그대로 결과에 포함시킨다.\n",
    "- 이 단순한 로직으로 리더보드 기준 약 1% 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m demo.ensemble_submission_parallel \\\n",
    "--result_files=work_dirs/fashion_detectors/e34.segm.json,work_dirs/fashion_detectors/e50.segm.json \\\n",
    "--output_dir=work_dirs/fashion_detectors/ens_e34_e50_softnms_scorethr081_ens_iouthr07 \\\n",
    "--iou_thr=0.7 \\\n",
    "--use_merge --n=10\n",
    "\n",
    "!head -n 2 work_dirs/fashion_detectors/ens_e34_e50_softnms_scorethr081_ens_iouthr07/submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 제출 파일 경로\n",
    "work_dirs/fashion_detectors/ens_e34_e50_softnms_scorethr081_ens_iouthr07/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l work_dirs/fashion_detectors/ens_e34_e50_softnms_scorethr081_ens_iouthr07/submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon_mmlab",
   "language": "python",
   "name": "dacon_mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
